{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "jBU6TETv-ad0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(\n",
        "    r\"^(?P<month>\\w{3})\\s+(?P<day>\\d{1,2})\\s+(?P<time>\\d{2}:\\d{2}:\\d{2})\\s+(?P<host>\\S+)\\s+(?P<process>[^\\[:]+)(?:\\[(?P<pid>\\d+)\\])?:\\s+(?P<message>.*)$\"\n",
        ")\n",
        "ALL_FIELDS = [\n",
        "    \"_time\", \"hostname\", \"process\", \"pid\", \"message\",\n",
        "    \"user\", \"file\", \"severity\", \"action\", \"command\", \"source_ip\", \"service\"\n",
        "]\n",
        "\n",
        "def parse_timestamp(month, day, time_str):\n",
        "    try:\n",
        "        year = datetime.now().year\n",
        "        dt = datetime.strptime(f\"{year} {month} {day} {time_str}\", \"%Y %b %d %H:%M:%S\")\n",
        "        return dt.isoformat()\n",
        "    except Exception as e:\n",
        "        #print(f\"Failed to parse timestamp: {month} {day} {time_str} â†’ {e}\")\n",
        "        return \"\"\n",
        "def extract_additional_fields(message):\n",
        "    fields = {}\n",
        "\n",
        "    #action\n",
        "    for action in ['Started', 'Stopped', 'Failed', 'Finished', 'Created', 'Mounted']:\n",
        "        if message.startswith(action):\n",
        "            fields['action'] = action\n",
        "            break\n",
        "\n",
        "    # User detection\n",
        "    user_match = re.search(r\"user(?:name)?=([^\\s]+)\", message)\n",
        "    if user_match:\n",
        "        fields['user'] = user_match.group(1)\n",
        "\n",
        "    # File detection\n",
        "    file_match = re.search(r\"(/\\S+)\", message)\n",
        "    if file_match:\n",
        "        fields['file'] = file_match.group(1)\n",
        "\n",
        "    # Source IP\n",
        "    ip_match = re.search(r\"from (\\d{1,3}(?:\\.\\d{1,3}){3})\", message)\n",
        "    if ip_match:\n",
        "        fields['source_ip'] = ip_match.group(1)\n",
        "\n",
        "    # Severity\n",
        "    if \"error\" in message.lower():\n",
        "        fields[\"severity\"] = \"error\"\n",
        "    elif \"warn\" in message.lower():\n",
        "        fields[\"severity\"] = \"warning\"\n",
        "    elif \"fail\" in message.lower():\n",
        "        fields[\"severity\"] = \"critical\"\n",
        "\n",
        "    return fields\n",
        "\n",
        "\n",
        "matchedCsv = \"structuredLogs.csv\"\n",
        "unmatchedCsv = \"unmathedLogs.csv\"\n",
        "\n",
        "with open(\"logs.txt\", \"r\") as infile, \\\n",
        "     open(matchedCsv, \"w\", newline=\"\") as outfile, \\\n",
        "     open(unmatchedCsv, \"w\") as unmatched_file:\n",
        "\n",
        "    writer = csv.DictWriter(outfile, fieldnames=ALL_FIELDS)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for line in infile:\n",
        "\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            data = match.groupdict()\n",
        "            row = dict.fromkeys(ALL_FIELDS, \"\")\n",
        "            #print(\"RAW LINE:\", line)\n",
        "           # print(\"MATCHED:\", data)\n",
        "            # Basic fields\n",
        "            row[\"_time\"] = parse_timestamp(data[\"month\"], data[\"day\"], data[\"time\"])\n",
        "            row[\"hostname\"] = data[\"host\"]\n",
        "            row[\"process\"] = data[\"process\"]\n",
        "            row[\"pid\"] = data.get(\"pid\") or \"\"\n",
        "            row[\"message\"] = data[\"message\"]\n",
        "\n",
        "            # Additional fields\n",
        "            extra = extract_additional_fields(data[\"message\"])\n",
        "            row.update(extra)\n",
        "\n",
        "            writer.writerow(row)\n",
        "        else:\n",
        "            unmatched_file.write(line)\n"
      ],
      "metadata": {
        "id": "jDBtJcqmz36e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "y6HlkjDgoJ2q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d6a1c1f5-55dc-473a-fb98-048b07cc06b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-3860162164.py:4: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(\"structuredLogs.csv\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_18e346ee-1a22-4c1d-92a4-7b059de17893\", \"filtered_logs.csv\", 7296)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "df = pd.read_csv(\"structuredLogs.csv\")\n",
        "\n",
        "\n",
        "df[\"_time\"] = pd.to_datetime(df[\"_time\"], errors=\"coerce\")\n",
        "\n",
        "\n",
        "target_time = datetime.strptime(\"2025-07-28 15:41:44\", \"%Y-%m-%d %H:%M:%S\")\n",
        "delta = timedelta(minutes=10)\n",
        "\n",
        "filtered = df[(df[\"_time\"] >= target_time - delta) & (df[\"_time\"] <= target_time + delta)]\n",
        "\n",
        "filtered.to_csv(\"filtered_logs.csv\", index=False)\n",
        "files.download(\"filtered_logs.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MgOopitQz2Vy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}